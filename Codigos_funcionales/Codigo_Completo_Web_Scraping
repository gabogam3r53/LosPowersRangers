import requests
from bs4 import BeautifulSoup
import csv
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import numpy as np

#Constantes
#csv_file = 'data.csv'
link_jugadoras_precio = 'https://www.spotrac.com/wnba/rankings/player/_/year/2024/sort/contract_value'

#Procedimientos iniciales
# Configurar el controlador de Selenium utilizando WebDriver Manager
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)


#Funciones

def obtener_jugadoras_y_precio(link):
    jugadoras = {'Nombre': [], 'Contrato' : []}
    r = requests.get(link) #Esto te da el codigo html de la pagina
    soup = BeautifulSoup(r.text, 'html.parser')
    links_nombres = soup.findAll('div', class_='link')
    links_montos = soup.findAll('span', class_= 'medium')
    for link_nombre,link_monto in zip(links_nombres,links_montos):
        #if separar(link_nombre) != "A'ja Wilson" and separar(link_nombre) != 'Azurá Stevens' and separar(link_nombre) != 'Stephanie Soares':
        jugadoras['Nombre'].append(separar(link_nombre))
        jugadoras['Contrato'].append(int((separar(link_monto).strip()[1:]).replace(",","")))
    df = pd.DataFrame(jugadoras)
    return df

def separar(link):
    link = str(link)
    start_tag = False
    for i in range(len(link)):
        if link[i] == '<' and not start_tag:
            start_tag = True
        elif link[i] == '>' and start_tag:
            index_start_information = i + 1
        elif link[i] == '<' and start_tag:
            index_stop_information = i
            start_tag = False
    return link[index_start_information:index_stop_information]

def obtener_equipo_fecha_fichaje(nombre_jugadora):
    #Pagina a navegar
    url = 'https://www.365scores.com/es'
    driver.get(url)
    
    # Esperar a que el botón de búsqueda esté presente y hacer clic en él
    try:
        boton_buscar = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, '.site-header_search_button__3pJPq'))
        )
        boton_buscar.click()
        print("Botón de búsqueda clickeado.")
    except Exception as e:
        print("No se pudo hacer clic en el botón de búsqueda:", e)
        return
    
    # Esperar a que el campo de búsqueda esté presente, hacer clic y añade el nombre de la jugadora
    try:
        
        
        campo_busqueda = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '.new-search-widget_input__aoNqC'))
        )
        
        campo_busqueda.click()
        campo_busqueda.send_keys(nombre_jugadora)
        time.sleep(2) #Se espera un poco para que cargue la jugadora a buscar
        campo_busqueda.send_keys(Keys.RETURN)  # Simular la tecla Enter
        print(f"Nombre de jugadora '{nombre_jugadora}' ingresado y búsqueda iniciada.")
    except Exception as e:
        print("No se pudo ingresar el nombre de la jugadora:", e)
        return
    try:   
        container = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, "new-search-widget_entity_item_intersection__L-eHP"))) 
        '''
        link_elemento = WebDriverWait(driver, 10).until(  #Le da click a la jugadora
            container.presence_of_element_located((By.CLASS_NAME, 'new-search-widget_entity_item_intersection__L-eHP'))
        )
        '''
        nombre_jugador_normalizado = nombre_jugadora.lower().replace(" ", "-")
        link = driver.find_element(By.XPATH, f".//a[contains(@class, 'new-search-widget_entity_item_intersection__L-eHP') and contains(@href, '{nombre_jugador_normalizado}')]")
        #container = driver.find_element(By.XPATH, ".//a[contains(@class, 'new-search-widget_entity_item_intersection__L-eHP') and contains(@href, '{nombre_jugadora}')]")
        #container = driver.find_element(By.CLASS_NAME, "new-search-widget_entity_item__Tthzc")
        #link_elemento = container.find_element(By.CLASS_NAME, 'new-search-widget_entity_item_intersection__L-eHP')
        #link_elemento.click()
        link.click()
    except Exception as e:
        print(f"No se pudo obtener el enlace o navegar al enlace de la jugadora '{nombre_jugadora}':", e)
        data = {
        'Nombre': [np.nan],
        'Fecha': [np.nan]
        }
    
        df = pd.DataFrame(data)
        return df
    
    #Se toma el contenedor que nos interesa y se guarda el html de este
    try:
        list_container = WebDriverWait(driver, 10).until(
        EC.visibility_of_element_located((By.CLASS_NAME, "list_container__AMVNC"))
        )

        html_content = list_container.get_attribute('innerHTML')
        
        # Se pasa el html a la libreria beautifulsoap para analizarlo
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Extraer la información de los elementos especificados
        nombres = soup.find_all('div', class_='ellipsis_container__ciMmU')
        fechas = soup.find_all('div', class_='athlete-widget_transfer_date__quLhJ')

        
        # Extraer el texto de cada elemento
        nombres_texto = [nombre.get_text(strip=True) for nombre in nombres]
        fechas_texto = [fecha.get_text(strip=True) for fecha in fechas]
        
        # Crear un DataFrame con la información extraída
        data = {
            'Nombre': nombres_texto,
            'Fecha': fechas_texto
        }
        
        df = pd.DataFrame(data)
        
        # Imprimir el DataFrame
        print("DataFrame con la información extraída:")
        return(df)
    except:
        print(f"Error con'{nombre_jugadora}'")
        data = {
        'Nombre': [np.nan],
        'Fecha': [np.nan]
        }
    
        df = pd.DataFrame(data)
        return df
    
def añadir_equipo_fecha_fichaje(df):
    columna = {'Equipo': [], 'Fecha fichaje': []}
    for jugadora in df.index:
        print(df['Nombre'][jugadora])
        informacion = obtener_equipo_fecha_fichaje(df['Nombre'][jugadora])
        columna['Equipo'].append(informacion['Nombre'][0])
        columna['Fecha fichaje'].append(informacion['Fecha'][0])
    nuevo_df = pd.DataFrame(columna)
    df_juntos = pd.concat([df,nuevo_df],axis=1)
    return df_juntos

data_jugadoras = obtener_jugadoras_y_precio(link_jugadoras_precio)
data_jugadoras_prueba = data_jugadoras.iloc[0:4]

data_jugadoras_completo = añadir_equipo_fecha_fichaje(data_jugadoras_prueba)
data_jugadoras_completo.to_csv('datos.csv', index=False, encoding='utf-8-sig')
data_jugadoras_completo.info(verbose=True)